import os
import torch
import torch.nn as nn
import torch.nn.functional as F
from collections import OrderedDict
from .base_trainer import BaseTrainer, AverageMeter


class FusionTrainer(BaseTrainer):
    """å¤šæ¨¡æ€èåˆè®­ç»ƒå™¨

    æ”¯æŒäººè„¸+æŒ‡çº¹ç‰¹å¾æå–å’Œèåˆè®­ç»ƒ
    æ”¯æŒåŠ è½½é¢„è®­ç»ƒçš„å•æ¨¡æ€æ¨¡å‹æƒé‡
    """

    def __init__(self, fusion_model, face_model, fingerprint_model,
                 train_loader, val_loader, optimizer, scheduler, criterion,
                 device, logger, tb_writer=None, pretrained_ckpts=None,
                 unfreeze_epoch=10, face_lr=1e-5, fp_lr=1e-5):
        """åˆå§‹åŒ–èåˆè®­ç»ƒå™¨

        Args:
            pretrained_ckpts: é¢„è®­ç»ƒæ£€æŸ¥ç‚¹è·¯å¾„å­—å…¸
            unfreeze_epoch: è§£å†»Backboneçš„è½®æ¬¡ (é»˜è®¤10è½®åè§£å†»)
            face_lr: è§£å†»åäººè„¸æ¨¡å‹çš„å­¦ä¹ ç‡
            fp_lr: è§£å†»åæŒ‡çº¹æ¨¡å‹çš„å­¦ä¹ ç‡
        """
        # ğŸ”§ ã€æŒ‡ä»¤Cã€‘ä¿å­˜è§£å†»ç­–ç•¥å‚æ•°
        self.unfreeze_epoch = unfreeze_epoch
        self.face_lr = face_lr
        self.fp_lr = fp_lr
        self.current_epoch = 0

        # åˆå§‹åŒ–çˆ¶ç±»
        super(FusionTrainer, self).__init__(
            fusion_model, train_loader, val_loader, optimizer, scheduler,
            criterion, device, logger, tb_writer
        )

        # å­˜å‚¨å•æ¨¡æ€æ¨¡å‹
        self.face_model = face_model.to(device) if face_model else None
        self.fingerprint_model = fingerprint_model.to(device) if fingerprint_model else None

        # åŠ è½½é¢„è®­ç»ƒæƒé‡
        if pretrained_ckpts:
            self._load_pretrained_weights(pretrained_ckpts)

        # ğŸ”§ ã€æŒ‡ä»¤Aã€‘éªŒè¯å•æ¨¡æ€å‡†ç¡®ç‡ (æœ€é‡è¦çš„"æ•‘å‘½ç¨»è‰")
        self._verify_unimodal_accuracy()

        # è®¾ç½®ç‰¹å¾æå–å™¨ä¸ºè¯„ä¼°æ¨¡å¼
        if self.face_model:
            self.face_model.eval()
        if self.fingerprint_model:
            self.fingerprint_model.eval()

        # å†»ç»“ç‰¹å¾æå–å™¨çš„å‚æ•°
        self._freeze_feature_extractors()

    def _load_pretrained_weights(self, pretrained_ckpts):
        """åŠ è½½é¢„è®­ç»ƒçš„å•æ¨¡æ€æ¨¡å‹æƒé‡ï¼ˆå¸¦å‰ç¼€å…¼å®¹æ€§å¤„ç†ï¼‰"""
        face_loaded = False
        fp_loaded = False

        if 'face' in pretrained_ckpts and pretrained_ckpts['face'] and self.face_model:
            face_ckpt_path = pretrained_ckpts['face']
            if os.path.exists(face_ckpt_path):
                try:
                    ckpt = torch.load(face_ckpt_path, map_location=self.device)

                    # è·å–æƒé‡å­—å…¸
                    if 'model_state' in ckpt:
                        state_dict = ckpt['model_state']
                    else:
                        state_dict = ckpt

                    # æ‰“å°åŸå§‹state_dictçš„keyï¼ˆç”¨äºè°ƒè¯•ï¼‰
                    keys = list(state_dict.keys())
                    self.logger.info(f"[Face] Checkpoint keys (first 5): {keys[:5]}")
                    self.logger.info(f"[Face] Model keys (first 5): {list(self.face_model.state_dict().keys())[:5]}")

                    # å¤„ç†å‰ç¼€å…¼å®¹æ€§é—®é¢˜
                    state_dict = self._adjust_state_dict_keys(state_dict, self.face_model.state_dict())

                    # åŠ è½½æƒé‡
                    self.face_model.load_state_dict(state_dict)

                    # éªŒè¯æƒé‡åŠ è½½æˆåŠŸ
                    with torch.no_grad():
                        test_input = torch.randn(1, 3, 224, 224).to(self.device)
                        test_feat = self.face_model.extract_features(test_input)
                        feat_norm = test_feat.norm().item()
                        self.logger.info(f"[Face] Pretrained weights loaded: {face_ckpt_path}")
                        self.logger.info(f"[Face] Feature norm: {feat_norm:.4f} (non-zero=success)")
                    face_loaded = True
                except Exception as e:
                    self.logger.warning(f"[Face] Failed to load weights: {e}")
            else:
                self.logger.warning(f"[Face] Checkpoint not found: {face_ckpt_path}")

        if 'fingerprint' in pretrained_ckpts and pretrained_ckpts['fingerprint'] and self.fingerprint_model:
            fp_ckpt_path = pretrained_ckpts['fingerprint']
            if os.path.exists(fp_ckpt_path):
                try:
                    ckpt = torch.load(fp_ckpt_path, map_location=self.device)

                    # è·å–æƒé‡å­—å…¸
                    if 'model_state' in ckpt:
                        state_dict = ckpt['model_state']
                    else:
                        state_dict = ckpt

                    # æ‰“å°åŸå§‹state_dictçš„keyï¼ˆç”¨äºè°ƒè¯•ï¼‰
                    keys = list(state_dict.keys())
                    self.logger.info(f"[FP] Checkpoint keys (first 5): {keys[:5]}")
                    self.logger.info(f"[FP] Model keys (first 5): {list(self.fingerprint_model.state_dict().keys())[:5]}")

                    # å¤„ç†å‰ç¼€å…¼å®¹æ€§é—®é¢˜
                    state_dict = self._adjust_state_dict_keys(state_dict, self.fingerprint_model.state_dict())

                    # åŠ è½½æƒé‡
                    self.fingerprint_model.load_state_dict(state_dict)

                    # éªŒè¯æƒé‡åŠ è½½æˆåŠŸ
                    with torch.no_grad():
                        test_input = torch.randn(1, 3, 224, 224).to(self.device)
                        test_feat = self.fingerprint_model.extract_features(test_input)
                        feat_norm = test_feat.norm().item()
                        self.logger.info(f"[FP] Pretrained weights loaded: {fp_ckpt_path}")
                        self.logger.info(f"[FP] Feature norm: {feat_norm:.4f} (non-zero=success)")
                    fp_loaded = True
                except Exception as e:
                    self.logger.warning(f"[FP] Failed to load weights: {e}")
            else:
                self.logger.warning(f"[FP] Checkpoint not found: {fp_ckpt_path}")

        # æ±‡æ€»
        if face_loaded and fp_loaded:
            self.logger.info("[OK] Face-Fingerprint alignment: paired samples share labels")
        else:
            self.logger.warning("[WARN] Using random weights or missing pretrained files")

    def _adjust_state_dict_keys(self, state_dict, target_model_dict):
        """è°ƒæ•´state_dictçš„keyå‰ç¼€ï¼Œå¤„ç†model.æˆ–backbone.ç­‰å‰ç¼€ä¸åŒ¹é…é—®é¢˜"""
        adjusted_state_dict = OrderedDict()
        target_keys = set(target_model_dict.keys())

        # å°è¯•ç›´æ¥åŒ¹é…
        matched_keys = set(state_dict.keys()) & target_keys
        if len(matched_keys) / len(target_keys) > 0.5:
            self.logger.info(f"[Weight] Direct match: {len(matched_keys)}/{len(target_keys)} keys")
            return state_dict

        # æ£€æŸ¥æ˜¯å¦éœ€è¦åˆ é™¤å‰ç¼€ï¼ˆå¦‚ model., backbone.ï¼‰
        for key, value in state_dict.items():
            # å°è¯•åˆ é™¤å¸¸è§å‰ç¼€
            new_key = key
            prefixes_to_remove = ['model.', 'backbone.', 'module.']
            for prefix in prefixes_to_remove:
                if key.startswith(prefix):
                    new_key = key[len(prefix):]
                    break

            # æ£€æŸ¥åˆ é™¤å‰ç¼€åæ˜¯å¦åŒ¹é…
            if new_key in target_keys:
                adjusted_state_dict[new_key] = value
            else:
                # å°è¯•æ·»åŠ å‰ç¼€
                added_prefix = False
                for prefix in prefixes_to_remove:
                    prefixed_key = prefix + key
                    if prefixed_key in target_keys:
                        adjusted_state_dict[prefixed_key] = value
                        added_prefix = True
                        break

                if not added_prefix:
                    # ä¿ç•™åŸå§‹keyï¼ˆå¯èƒ½æœ‰éƒ¨åˆ†å±‚ä¸åŒ¹é…ï¼‰
                    adjusted_state_dict[key] = value

        # ç»Ÿè®¡åŒ¹é…æƒ…å†µ
        matched = sum(1 for k in adjusted_state_dict.keys() if k in target_keys)
        self.logger.info(f"[Weight] Adjusted: {matched}/{len(target_keys)} keys matched")
        return adjusted_state_dict

    def _verify_unimodal_accuracy(self):
        """ğŸ”§ ã€æŒ‡ä»¤Aã€‘éªŒè¯å•æ¨¡æ€å‡†ç¡®ç‡ (æœ€é‡è¦çš„"æ•‘å‘½ç¨»è‰")

        åœ¨éªŒè¯é›†ä¸Šæµ‹è¯•äººè„¸å’ŒæŒ‡çº¹å„è‡ªçš„åˆ†ç±»å‡†ç¡®ç‡
        - åŠ è½½æ­£ç¡®: åº”è¯¥æœ‰åˆç†çš„å‡†ç¡®ç‡ (>20% for 300 classes)
        - åŠ è½½å¤±è´¥: å‡†ç¡®ç‡æ¥è¿‘éšæœº (~0.3% for 300 classes)
        """
        self.logger.info("=" * 60)
        self.logger.info("[éªŒè¯] å¼€å§‹éªŒè¯å•æ¨¡æ€æƒé‡åŠ è½½...")
        self.logger.info("=" * 60)

        # ä¸´æ—¶åˆ›å»ºArcFaceåˆ†ç±»å™¨ç”¨äºæµ‹è¯•
        num_classes = self.model.num_classes if hasattr(self.model, 'num_classes') else 300

        # éªŒè¯äººè„¸æ¨¡å‹
        face_acc = self._test_unimodal_accuracy(
            self.face_model,
            "äººè„¸",
            num_classes
        )

        # éªŒè¯æŒ‡çº¹æ¨¡å‹
        fp_acc = self._test_unimodal_accuracy(
            self.fingerprint_model,
            "æŒ‡çº¹",
            num_classes
        )

        # æ±‡æ€»ç»“æœ
        self.logger.info("=" * 60)
        self.logger.info("[FusionTrainer] [STATS] å•æ¨¡æ€éªŒè¯ç»“æœæ±‡æ€»:")
        self.logger.info(f"[FusionTrainer]   äººè„¸æ¨¡å‹ Acc: {face_acc*100:.2f}%")
        self.logger.info(f"[FusionTrainer]   æŒ‡çº¹æ¨¡å‹ Acc: {fp_acc*100:.2f}%")
        self.logger.info("=" * 60)

        # è­¦å‘Š
        if face_acc < 0.05:
            self.logger.warning("[è­¦å‘Š] äººè„¸æ¨¡å‹å‡†ç¡®ç‡è¿‡ä½ï¼Œæƒé‡å¯èƒ½æœªæ­£ç¡®åŠ è½½ï¼")
        if fp_acc < 0.05:
            self.logger.warning("[è­¦å‘Š] æŒ‡çº¹æ¨¡å‹å‡†ç¡®ç‡è¿‡ä½ï¼Œæƒé‡å¯èƒ½æœªæ­£ç¡®åŠ è½½ï¼")

    def _test_unimodal_accuracy(self, model, modality_name, num_classes):
        """æµ‹è¯•å•æ¨¡æ€æ¨¡å‹åœ¨éªŒè¯é›†ä¸Šçš„å‡†ç¡®ç‡"""
        if model is None:
            self.logger.warning(f"[FusionTrainer] {modality_name}æ¨¡å‹ä¸å­˜åœ¨")
            return 0.0

        try:
            from ..losses.arcface import ArcMarginProduct

            # åˆ›å»ºArcFaceåˆ†ç±»å™¨ (ä¸å•æ¨¡æ€è®­ç»ƒä¸€è‡´)
            classifier = ArcMarginProduct(
                in_features=model.embedding_dim if hasattr(model, 'embedding_dim') else 512,
                out_features=num_classes,
                s=30.0,
                m=0.3
            ).to(self.device)

            # åœ¨éªŒè¯é›†ä¸Šæµ‹è¯•
            correct = 0
            total = 0

            for batch in self.val_loader:
                images = batch['face_image' if modality_name == 'äººè„¸' else 'fingerprint_image'].to(self.device)
                labels = batch['label'].to(self.device)

                with torch.no_grad():
                    # æå–ç‰¹å¾
                    if hasattr(model, 'extract_features'):
                        features = model.extract_features(images)
                    else:
                        features = model._extract_features(images)

                    # è®¡ç®—logits
                    logits = classifier(features, labels)
                    preds = logits.argmax(dim=1)

                    correct += (preds == labels).sum().item()
                    total += labels.size(0)

            acc = correct / total if total > 0 else 0.0
            self.logger.info(f"[FusionTrainer] [OK] {modality_name}æ¨¡å‹å•æ¨¡æ€éªŒè¯å®Œæˆ: Acc={acc*100:.2f}%")
            return acc

        except Exception as e:
            self.logger.warning(f"[FusionTrainer] âŒ {modality_name}æ¨¡å‹éªŒè¯å¤±è´¥: {e}")
            return 0.0

    def _freeze_feature_extractors(self):
        """å†»ç»“ç‰¹å¾æå–å™¨å‚æ•°"""
        if self.face_model:
            for param in self.face_model.parameters():
                param.requires_grad = False
            self.logger.info("[å†»ç»“] äººè„¸æ¨¡å‹å‚æ•°å·²å†»ç»“")
        if self.fingerprint_model:
            for param in self.fingerprint_model.parameters():
                param.requires_grad = False
            self.logger.info("[å†»ç»“] æŒ‡çº¹æ¨¡å‹å‚æ•°å·²å†»ç»“")

    def _unfreeze_backbone_partial(self):
        """ğŸ”§ ã€æŒ‡ä»¤Cã€‘éƒ¨åˆ†è§£å†»Backbone (ä»…æœ€åä¸¤å±‚)

        è§£å†»äººè„¸ResNet50å’ŒæŒ‡çº¹ResNet34çš„æœ€åä¸¤å±‚å·ç§¯å±‚
        è®¾ç½®æå°çš„å­¦ä¹ ç‡è¿›è¡Œè”åˆå¾®è°ƒ
        """
        self.logger.info("=" * 60)
        self.logger.info(f"[è§£å†»] Epoch {self.current_epoch + 1}: å¼€å§‹éƒ¨åˆ†è§£å†»Backbone...")
        self.logger.info("=" * 60)

        if self.face_model:
            # è§£å†»ResNet50æœ€åä¸¤å±‚ (layer3, layer4)
            unfrozen_layers = []
            layer3_unfrozen = False
            layer4_unfrozen = False

            for name, param in self.face_model.named_parameters():
                if 'layer3' in name or 'layer4' in name:
                    param.requires_grad = True
                    if 'layer3' in name and not layer3_unfrozen:
                        unfrozen_layers.append('layer3')
                        layer3_unfrozen = True
                    elif 'layer4' in name and not layer4_unfrozen:
                        unfrozen_layers.append('layer4')
                        layer4_unfrozen = True

            self.logger.info(f"[è§£å†»] äººè„¸æ¨¡å‹è§£å†»å±‚: {unfrozen_layers}")

        if self.fingerprint_model:
            # è§£å†»ResNet34æœ€åä¸¤å±‚ (layer3, layer4)
            unfrozen_layers = []
            layer3_unfrozen = False
            layer4_unfrozen = False

            for name, param in self.fingerprint_model.named_parameters():
                if 'layer3' in name or 'layer4' in name:
                    param.requires_grad = True
                    if 'layer3' in name and not layer3_unfrozen:
                        unfrozen_layers.append('layer3')
                        layer3_unfrozen = True
                    elif 'layer4' in name and not layer4_unfrozen:
                        unfrozen_layers.append('layer4')
                        layer4_unfrozen = True

            self.logger.info(f"[è§£å†»] æŒ‡çº¹æ¨¡å‹è§£å†»å±‚: {unfrozen_layers}")

        self.logger.info("[FusionTrainer] [INFO] è¯·ä½¿ç”¨æ›´å°çš„å­¦ä¹ ç‡å¾®è°ƒ (å»ºè®®: backbone=1e-5, fusion=1e-4)")

    @torch.no_grad()
    def _extract_features(self, face_images, fingerprint_images):
        """ä»ä¸¤ä¸ªæ¨¡æ€æå–ç‰¹å¾ï¼ŒåŒ…å«NaNæ£€æŸ¥å’ŒL2å½’ä¸€åŒ–"""
        # æå–äººè„¸ç‰¹å¾
        if self.face_model:
            face_features = self.face_model.extract_features(face_images)
        else:
            # å¦‚æœæ²¡æœ‰äººè„¸æ¨¡å‹ï¼Œä½¿ç”¨éšæœºç‰¹å¾ï¼ˆç”¨äºæµ‹è¯•ï¼‰
            face_features = torch.randn(face_images.size(0), 512, device=self.device)

        # æå–æŒ‡çº¹ç‰¹å¾
        if self.fingerprint_model:
            fingerprint_features = self.fingerprint_model.extract_features(fingerprint_images)
        else:
            # å¦‚æœæ²¡æœ‰æŒ‡çº¹æ¨¡å‹ï¼Œä½¿ç”¨éšæœºç‰¹å¾ï¼ˆç”¨äºæµ‹è¯•ï¼‰
            fingerprint_features = torch.randn(fingerprint_images.size(0), 256, device=self.device)

        # ğŸ”§ ã€æŒ‡ä»¤Aã€‘å¼ºåˆ¶L2å½’ä¸€åŒ– - ç¨³å®šæ•°å€¼åˆ†å¸ƒ
        face_features = F.normalize(face_features, p=2, dim=1)
        fingerprint_features = F.normalize(fingerprint_features, p=2, dim=1)

        # ğŸ”§ ã€æŒ‡ä»¤Aã€‘NaN/Infæ£€æŸ¥
        if torch.isnan(face_features).any() or torch.isinf(face_features).any():
            self.logger.warning("[FusionTrainer] æ£€æµ‹åˆ°äººè„¸ç‰¹å¾åŒ…å«NaN/Infï¼Œä½¿ç”¨é›¶å‘é‡æ›¿æ¢")
            face_features = torch.where(
                torch.isnan(face_features) | torch.isinf(face_features),
                torch.zeros_like(face_features),
                face_features
            )

        if torch.isnan(fingerprint_features).any() or torch.isinf(fingerprint_features).any():
            self.logger.warning("[FusionTrainer] æ£€æµ‹åˆ°æŒ‡çº¹ç‰¹å¾åŒ…å«NaN/Infï¼Œä½¿ç”¨é›¶å‘é‡æ›¿æ¢")
            fingerprint_features = torch.where(
                torch.isnan(fingerprint_features) | torch.isinf(fingerprint_features),
                torch.zeros_like(fingerprint_features),
                fingerprint_features
            )

        return face_features, fingerprint_features

    def train_epoch(self, epoch):
        """è®­ç»ƒä¸€ä¸ªepoch"""
        # ğŸ”§ ã€æŒ‡ä»¤Cã€‘æ›´æ–°å½“å‰epoch
        self.current_epoch = epoch

        # ğŸ”§ ã€æŒ‡ä»¤Cã€‘æ£€æŸ¥æ˜¯å¦éœ€è¦è§£å†»Backbone
        if epoch == self.unfreeze_epoch:
            self._unfreeze_backbone_partial()

        self.model.train()
        # ç‰¹å¾æå–å™¨ä¿æŒåœ¨è¯„ä¼°æ¨¡å¼ï¼ˆé™¤éå·²è§£å†»ï¼‰
        if self.face_model:
            self.face_model.eval()
        if self.fingerprint_model:
            self.fingerprint_model.eval()

        loss_meter = AverageMeter()
        acc_meter = AverageMeter()

        from tqdm import tqdm
        pbar = tqdm(self.train_loader, desc=f"Epoch {epoch+1} [Fusion Train]", leave=False)

        for batch_idx, batch in enumerate(pbar):
            face_images = batch['face_image'].to(self.device)
            fingerprint_images = batch['fingerprint_image'].to(self.device)
            targets = batch['label'].to(self.device)

            # æå–ä¸¤ä¸ªæ¨¡æ€çš„ç‰¹å¾
            face_features, fingerprint_features = self._extract_features(face_images, fingerprint_images)

            # å‰å‘ä¼ æ’­é€šè¿‡èåˆæ¨¡å‹ (å¸¦labelsä»¥å¯ç”¨ArcFace)
            outputs = self.model(face_features, fingerprint_features, targets)
            loss = self.criterion(outputs, targets)

            # åå‘ä¼ æ’­
            self.optimizer.zero_grad()
            loss.backward()
            self.optimizer.step()

            # è®¡ç®—å‡†ç¡®ç‡
            preds = outputs.argmax(dim=1)
            acc = (preds == targets).float().mean().item()

            loss_meter.update(loss.item(), face_images.size(0))
            acc_meter.update(acc, face_images.size(0))

            pbar.set_postfix({"loss": f"{loss_meter.avg:.4f}", "acc": f"{acc_meter.avg:.4f}"})

        self.logger.info(f"[è®­ç»ƒ] Epoch {epoch+1}: Loss={loss_meter.avg:.4f}, å‡†ç¡®ç‡={acc_meter.avg:.4f}")
        return loss_meter.avg, acc_meter.avg

    @torch.no_grad()
    def validate_epoch(self, epoch):
        """éªŒè¯ä¸€ä¸ªepoch"""
        self.model.eval()
        if self.face_model:
            self.face_model.eval()
        if self.fingerprint_model:
            self.fingerprint_model.eval()

        loss_meter = AverageMeter()
        acc_meter = AverageMeter()

        from tqdm import tqdm
        pbar = tqdm(self.val_loader, desc=f"Epoch {epoch+1} [Fusion Val]", leave=False)

        all_preds = []
        all_labels = []

        for batch in pbar:
            face_images = batch['face_image'].to(self.device)
            fingerprint_images = batch['fingerprint_image'].to(self.device)
            targets = batch['label'].to(self.device)

            # æå–ç‰¹å¾
            face_features, fingerprint_features = self._extract_features(face_images, fingerprint_images)

            # å‰å‘ä¼ æ’­ (å¸¦labelsä»¥å¯ç”¨ArcFace)
            outputs = self.model(face_features, fingerprint_features, targets)
            loss = self.criterion(outputs, targets)

            # è®¡ç®—å‡†ç¡®ç‡
            preds = outputs.argmax(dim=1)
            acc = (preds == targets).float().mean().item()

            loss_meter.update(loss.item(), face_images.size(0))
            acc_meter.update(acc, face_images.size(0))

            all_preds.extend(preds.cpu().tolist())
            all_labels.extend(targets.cpu().tolist())

            pbar.set_postfix({"loss": f"{loss_meter.avg:.4f}", "acc": f"{acc_meter.avg:.4f}"})

        # è®¡ç®—è¯¦ç»†æŒ‡æ ‡
        try:
            from sklearn.metrics import precision_score, recall_score, f1_score
            precision = precision_score(all_labels, all_preds, average='macro', zero_division=0)
            recall = recall_score(all_labels, all_preds, average='macro', zero_division=0)
            f1 = f1_score(all_labels, all_preds, average='macro', zero_division=0)
        except Exception:
            precision = recall = f1 = 0.0

        metrics = {"precision": precision, "recall": recall, "f1_score": f1}
        self.logger.info(f"[éªŒè¯] Epoch {epoch+1}: Loss={loss_meter.avg:.4f}, å‡†ç¡®ç‡={acc_meter.avg:.4f}, ç²¾ç¡®ç‡={precision:.4f}, å¬å›ç‡={recall:.4f}, F1={f1:.4f}")
        return loss_meter.avg, acc_meter.avg, metrics

    def save_checkpoint(self, path, is_best=False, extra=None):
        """ä¿å­˜æ£€æŸ¥ç‚¹ï¼ˆä»…æœ€ä½³æ¨¡å‹ï¼‰"""
        checkpoint = {
            'fusion_model': self.model.state_dict(),
            'optimizer': self.optimizer.state_dict(),
            'scheduler': self.scheduler.state_dict() if self.scheduler else None,
        }

        if extra:
            checkpoint.update(extra)

        # åªä¿å­˜æœ€ä½³æ¨¡å‹
        if is_best:
            torch.save(checkpoint, path)
            self.logger.info(f"[ä¿å­˜] æœ€ä½³æ¨¡å‹: {path}")
        else:
            # ä¸´æ—¶ä¿å­˜Latestç”¨äºæ¢å¤è®­ç»ƒ
            latest_path = path.replace(".pth", "_latest.pth")
            torch.save(checkpoint, latest_path)

    def load_checkpoint(self, path):
        """åŠ è½½æ£€æŸ¥ç‚¹"""
        checkpoint = torch.load(path, map_location=self.device)

        self.model.load_state_dict(checkpoint['fusion_model'])
        self.optimizer.load_state_dict(checkpoint['optimizer'])

        if self.scheduler and checkpoint.get('scheduler'):
            self.scheduler.load_state_dict(checkpoint['scheduler'])

        self.logger.info(f"åŠ è½½èåˆæ¨¡å‹æ£€æŸ¥ç‚¹: {path}")
        return checkpoint